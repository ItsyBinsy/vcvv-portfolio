# ğŸ›¡ï¸ Rate Limiting Documentation

## Overview
This portfolio implements **two-layer rate limiting** to prevent API abuse and control OpenAI costs.

---

## ğŸ¯ Rate Limits (Generous)

### Server-Side (API)
- **10 messages per minute** per IP address
- **50 messages per hour** per IP address
- Returns `429 Too Many Requests` when exceeded

### Client-Side (Frontend)
- **3-second cooldown** between consecutive messages
- Prevents accidental spam/double-clicks
- Shows friendly countdown message

---

## ğŸ”§ Implementation

### Server (`/api/chat.js`)
```javascript
// In-memory rate limiter
const rateLimit = new Map();
- Tracks requests by IP address
- Automatically cleans expired entries
- Returns error message with reset time
```

**Limits:**
```javascript
maxPerMinute = 10
maxPerHour = 50
```

### Client (`src/components/Chatbot.jsx`)
```javascript
// State management
const [lastMessageTime, setLastMessageTime] = useState(0);
const cooldown = 3000; // 3 seconds
```

---

## ğŸš¨ Error Messages

### Client-Side Cooldown
```
"Please wait X second(s) before sending another message."
```

### Server-Side Rate Limit
```
"Rate limit exceeded. Please wait a minute/hour before sending more messages."
```

### Bot Response
```
"Whoa, you're asking a lot of questions! ğŸ˜… Please wait a moment before continuing our chat."
```

---

## ğŸ“Š Why These Limits?

### Generous for Portfolio
- **Normal visitors:** 10 questions/minute is plenty for browsing
- **Recruiters:** Can have extended conversations without hitting limits
- **Cost protection:** 50 messages/hour prevents $5 credit drain

### Calculation
```
Worst case: 50 messages/hour Ã— 24 hours = 1,200 messages/day
Cost: ~$0.18/day (well within $5 budget)
```

---

## ğŸ”„ Resets

### In-Memory (Current Implementation)
- **Resets on:** Vercel function cold start (~15 min inactivity)
- **Pros:** Simple, no dependencies, good for portfolio traffic
- **Cons:** Resets periodically (actually a feature!)

### Future: Persistent Storage
If traffic increases, consider:
- **Upstash Redis** (free tier, persistent)
- **Vercel KV** (key-value store)
- **Database** (PostgreSQL, MongoDB)

---

## âœ… Testing Rate Limits

### Test Client-Side (3s cooldown)
1. Open chatbot
2. Send message
3. Try sending immediately â†’ Should show cooldown message

### Test Server-Side (10/min)
1. Open browser console
2. Run this script:
```javascript
for(let i=0; i<12; i++) {
  fetch('/api/chat', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({message: 'test'})
  }).then(r => console.log(i, r.status));
}
```
3. Should see `429` after 10 requests

---

## ğŸ¨ User Experience

### Smooth UX
- âœ… Error messages are friendly, not technical
- âœ… Shows countdown timer on client-side
- âœ… Bot responds with personality even when rate-limited
- âœ… No harsh blocking, just gentle slowdown

### Visual Feedback
- Error appears as red toast notification
- Auto-dismisses after 2 seconds
- Doesn't break chat flow

---

## ğŸ” Security Features

1. **IP-based tracking** - Uses `x-forwarded-for` header
2. **Fallback to 'anonymous'** - Handles missing IP gracefully
3. **Both client & server** - Defense in depth
4. **Automatic cleanup** - Old entries expire automatically

---

## ğŸ’¡ Future Enhancements

If needed:
- [ ] Add daily limits (e.g., 200/day)
- [ ] Track by session ID instead of IP
- [ ] Whitelist certain IPs (recruiters, etc.)
- [ ] Analytics dashboard for rate limit hits
- [ ] Exponential backoff for repeat offenders

---

## ğŸ“ Notes

**Why not use a library?**
- Portfolio doesn't need external dependencies
- In-memory solution is simpler for low traffic
- Easy to upgrade later if needed

**Why generous limits?**
- Portfolio should be welcoming, not restrictive
- Recruiters might ask many questions (good thing!)
- Still prevents abuse while allowing exploration

---

âœ… **Status:** Implemented & Production Ready
ğŸš€ **Performance:** Minimal overhead (~1ms per request)
ğŸ’° **Cost Savings:** Prevents $5 credit drain
